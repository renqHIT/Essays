# 机器学习的“万能模板”之：桑坦德银行推荐

标签（空格分隔）： 机器学习

---

前些天翻译整理了一篇博客，原题目为《Approaching Almost Any Machine Learning Problem》，发在[数据极客论坛][1]。文中介绍了用几个核心的Python库处理常见机器学习问题的一般套路，总体来说是一个不错的实践方案。这篇文章，我们以最近一期的Kaggle比赛为例，进一步检验一下模板的效果。

---

西班牙的桑坦德银行举办了这次比赛：[Santander银行产品预测][2]。比赛提供了银行用户的个人基本信息和过去一年的用户行为，想要预测下一年用户会新增哪些银行产品。数据字段如下：

#TODO 整理中文

|Column Name|	Description|
|---|---|
|fecha_dato|	The table is partitioned for this column|
|ncodpers|	Customer code|
|ind_empleado|	Employee index: A active, B ex employed, F filial, N not employee, P pasive|
|pais_residencia|	Customer's Country residence|
|sexo|	Customer's sex|
|age|	Age|
|fecha_alta|	The date in which the customer became as the first holder of a contract in the bank|
|ind_nuevo|	New customer Index. 1 if the customer registered in the last 6 months.|
|antiguedad	Customer seniority (in months)
|indrel|	1 (First/Primary), 99 (Primary customer during the month but not at the end of the month)|
|ult_fec_cli_1t|	Last date as primary customer (if he isn't at the end of the month)|
|indrel_1mes|	Customer type at the beginning of the month ,1 (First/Primary customer), 2 (co-owner ),P (Potential),3 (former primary), 4(former co-owner)|
|tiprel_1mes|	Customer relation type at the beginning of the month, A (active), I (inactive), P (former customer),R (Potential)|
|indresi|	Residence index (S (Yes) or N (No) if the residence country is the same than the bank country)|
|indext	|Foreigner index (S (Yes) or N (No) if the customer's birth country is different than the bank country)|
|conyuemp|	Spouse index. 1 if the customer is spouse of an employee|
|canal_entrada|	channel used by the customer to join|
|indfall|	Deceased index. N/S|
|tipodom|	Addres type. 1, primary address|
|cod_prov|	Province code (customer's address)|
|nomprov|	Province name|
|ind_actividad_cliente|	Activity index (1, active customer; 0, inactive customer)|
|renta|	Gross income of the household|
|segmento	|segmentation: 01 - VIP, 02 - Individuals 03 - college graduated|
|ind_ahor_fin_ult1|	Saving Account|
|ind_aval_fin_ult1|	Guarantees|
|ind_cco_fin_ult1|	Current Accounts|
|ind_cder_fin_ult1|	Derivada Account|
|ind_cno_fin_ult1|	Payroll Account|
|ind_ctju_fin_ult1|	Junior Account|
|ind_ctma_fin_ult1	|Más particular Account|
|ind_ctop_fin_ult1|	particular Account|
|ind_ctpp_fin_ult1|	particular Plus Account|
|ind_deco_fin_ult1|	Short-term deposits|
|ind_deme_fin_ult1|	Medium-term deposits|
|ind_dela_fin_ult1|	Long-term deposits|
|ind_ecue_fin_ult1|	e-account|
|ind_fond_fin_ult1|	Funds|
|ind_hip_fin_ult1|	Mortgage|
|ind_plan_fin_ult1|	Pensions|
|ind_pres_fin_ult1|	Loans|
|ind_reca_fin_ult1|	Taxes|
|ind_tjcr_fin_ult1|	Credit Card|
|ind_valo_fin_ult1|	Securities|
|ind_viv_fin_ult1|	Home Account|
|ind_nomina_ult1|	Payroll|
|ind_nom_pens_ult1|	Pensions|
|ind_recibo_ult1|	Direct Debit|

预测结果的评价指标为：Mean Average Precision @ 7 (MAP@7):

![image_1b3pnf8vss3k1pu91eov1kli1ivc9.png-9.5kB][3]

# TODO: 分析MAP@7指标的含义

上文的结尾，我们总结了如下步骤：

 1. 识别问题的类型，数据分割成两部分：训练集，验证集
 2. 识别数据中的变量，形成特征
 3. 正则化特征，选择特征
 4. 选择模型，优化超参数
 5. 保存转换器



首先使用pandas浏览数据
```Python
>>> import pandas as pd
>>> test = pd.read_csv('/home/data/SanRecommend/data/test_ver2.csv')
>>> test.head()
   fecha_dato  ncodpers ind_empleado pais_residencia sexo  age  fecha_alta  \
0  2016-06-28     15889            F              ES    V   56  1995-01-16   
1  2016-06-28   1170544            N              ES    H   36  2013-08-28   
2  2016-06-28   1170545            N              ES    V   22  2013-08-28   
3  2016-06-28   1170547            N              ES    H   22  2013-08-28   
4  2016-06-28   1170548            N              ES    H   22  2013-08-28   

   ind_nuevo  antiguedad  indrel         ...         indext  conyuemp  \
0          0         256       1         ...              N         N   
1          0          34       1         ...              N       NaN   
2          0          34       1         ...              N       NaN   
3          0          34       1         ...              N       NaN   
4          0          34       1         ...              N       NaN   

  canal_entrada indfall tipodom cod_prov         nomprov  \
0           KAT       N       1     28.0          MADRID   
1           KAT       N       1      3.0        ALICANTE   
2           KHE       N       1     15.0       CORUÑA, A   
3           KHE       N       1      8.0       BARCELONA   
4           KHE       N       1      7.0  BALEARS, ILLES   

  ind_actividad_cliente        renta            segmento  
0                     1    326124.90            01 - TOP  
1                     0           NA   02 - PARTICULARES  
2                     1           NA  03 - UNIVERSITARIO  
3                     0    148402.98  03 - UNIVERSITARIO  
4                     0    106885.80  03 - UNIVERSITARIO  

[5 rows x 24 columns]
```

按“数值变量”“文本变量”“类别变量”， 人工标注数据变量的类别。
|变量名|样例|变量类别|
|---|---|---|
|ncodpers|15889|***ID***|
|fecha_dato |2016-06-28|***日期***|
|fecha_alta|1995-01-16|***日期***|
|ind_empleado|F|类别变量|
|pais_residencia|ES|类别变量|
|sexo|V|类别变量|
|ind_nuevo|0|类别变量|
|indrel|1|类别变量|
|indext|N|类别变量|
|conyuemp|N|类别变量|
|canal_entrada|KAT|类别变量|
|indfall|N|类别变量|
|tipodom|1|类别变量|
|nomprov|MADRID|类别变量|
|ind_actividad_cliente|1|类别变量|
|segmento|01 - TOP|类别变量|
|antiguedad|256|数值变量|
|age|56|数值变量|
|cod_prov|28.0|数值变量|
|renta|326124.90|数值变量|

这里我们遇到了两个问题： 1. ID，算哪种类型？ 2. 时间，算哪一种类型？

**留作思考题吧**

LabelEncoding

```Python
>>> lbl_enc.fit(test['segmento'])
LabelEncoder()
>>> test_cat = lbl_enc.transform(test['segmento'])
>>> test_cat
array([1, 2, 3, ..., 2, 2, 2])
```

```Python
>>> categorical_features = ['ind_empleado', 'pais_residencia', 'sexo', 'ind_nuevo', 'indrel', 'indext', 'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'nomprov', 'ind_actividad_cliente', 'segmento']
>>> numerical_features = ['antiguedad', 'age', 'cod_prov', 'renta']
```

```Python
>>> featured_test = {}
>>> for feature in categorical_features:
...     lbl_enc.fit(test[feature])
...     featured_test[feature] = lbl_enc.transform(test[feature])
...     print feature, featured_test[feature]
...     
```
如果遇到这种错误,
```Python
Traceback (most recent call last):
  File "<stdin>", line 3, in <module>
  File "/home/renq/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/label.py", line 148, in transform
    raise ValueError("y contains new labels: %s" % str(diff))
ValueError: y contains new labels: [nan nan nan ..., nan nan nan]
>>>
```
我们应该回头处理下数据（NaN，即Not a Number）, 例如，用0填充

```Python
test.fillna(0, inplace=True)
```
如果一切顺利，你应该可以得到
```Python
ind_empleado [2 3 3 ..., 3 3 3]
pais_residencia [36 36 36 ..., 36 36 36]
sexo [2 1 2 ..., 2 2 2]
ind_nuevo [0 0 0 ..., 0 0 0]
indrel [0 0 0 ..., 0 0 0]
indext [0 0 0 ..., 0 0 0]
conyuemp [1 0 0 ..., 0 0 0]


canal_entrada [ 25  25 151 ...,  51 123  25]
indfall [0 0 0 ..., 0 0 0]
tipodom [0 0 0 ..., 0 0 0]
nomprov [31  3 19 ...,  5  5 48]
ind_actividad_cliente [1 0 1 ..., 1 0 0]
segmento [1 2 3 ..., 2 2 2]
```
这样类别属性已经转换成了数字，我们可以进行下一步了，正则化特征，选择特征。

---

### 3. 正则化特征，特征选择

然后，我们来到了栈模块（stack module），这里的栈不是模型栈而是特征栈。在经过上一步的处理后，我们得到了不同的特征。

根据你得到的是稠密特征还是稀疏特征，你可以使用numpy模块的hstack或者sparse hstack把所有特征存进一个栈。

![特征栈][4]

如果还有其他处理过程，比如PCA或者特征选择，我们还可以使用FeatureUnion模块。本文后面会继续提到分解和特征选择。

![FeatureUnion][5]

结果如下，
```Python
hstack:  ['ind_empleado' 'pais_residencia' 'sexo' 'ind_nuevo' 'indrel' 'indext'
 'conyuemp' 'canal_entrada' 'indfall' 'tipodom' 'nomprov'
 'ind_actividad_cliente' 'segmento']
skb:  SelectKBest(k=1, score_func=<function f_classif at 0x7fb3fc31cf50>)
combined features:  FeatureUnion(n_jobs=1,
       transformer_list=[('pca', PCA(copy=True, n_components=10, whiten=False)), ('skb', SelectKBest(k=1, score_func=<function f_classif at 0x7fb3fc31cf50>))],
       transformer_weights=None)
```

有了上面的特征，我们就可以开始应用机器学习模型了。现阶段，你只需要考虑基于树的模型就足够了。这些模型包括：

 - 随机森林分类器 RandomForestClassifier
 - 随机森林回归器 RandomForestRegressor
 - ExtraTreesClassifier
 - ExtraTreesRegressor
 - XGBClassifier
 - XGBRegressor

在直接使用上面的特征之前，首先需要进行正则化。对于使用线性模型而言，我们可以选择scikit-learn中的Normalizer或者StandardScaler。这些正则方法只针对稠密特征有效，在稀疏特征上不会给出好的结果。

假如上面的过程得到了一个“好的”模型，那我们可以继续优化超参数；假如没有得到
“足够好的”模型，我们可以通过下面的方法继续优化模型。

下一步包含分解方法：

**PCA**
![分解方法][6]

为了简单起见，我们不谈LDA和QDA变换。对高维数据，一般采用PCA算法分解数据。对图片数据，我们从10-15个components开始逐渐增加，直到结果质量充分提高；对其他类型数据，我们初始选择50-60个components。

![PCA][7]

**SVD**
对于文本数据，在文本转换成稀疏矩阵后，使用奇异值分解(Singular Value Decomposition, SVD)转换数据。Scikit-learn提供了一份SVD的变种算法TruncatedSVD。

![SVD][8]

对于TF-IDF或者count向量化方法，SVD的components个数选择120-200之间一般是有效果的。更高的components个数会提高效果，但也需要更高的计算代价。

**贪心特征选择**
有多种方法达到特征选择的目的，其中最常见的一个是贪心特征选择（向前或向后）。在贪心特征选择中，我们选择一个特征，训练一个模型，然后在一项固定的指标上评估模型表现。然后我们一个一个地添加或者删除特征，记录每一步中模型的表现。最后选择让模型表现最好的特征集。贪心特征选择的一种实现，可以参考[这里][9]

**Gradient Boosting Machine**
特征选择还可以通过Gradient Boosting Machine达到。推荐使用xgboost代替scikit-learn中的GBM实现，因为xgboost更快而且更加具有可伸缩性。

![xgboost][10]

### 4. 模型选择，超参数优化

我们一般采用下面的算法选择机器学习模型：

 - 分类
    - 随机森林 Random Forest
    - GBM
    - 逻辑回归 Logistic Regression
    - 朴素贝叶斯 Naive Bayes
    - 支持向量机 Support Vector Machine
    - k近邻 k-Nearest Neighbors
 - 回归
    - 随机森林 Random Forest
    - GBM
    - 线性回归 Linear Regression
    - 岭回归 Ridge
    - Lasso
    - SVR

下面是作者给出他建议的模型和相对应的经验参数值，参数的选择经过时间和数据的积累。作者号称，上面的模型和参数组合已经超过了其他所有的模型。

![参数表][11]
    
### 5. 保存转换器

最后，记得保存转换器，在验证集应用训练出的模型。

![验证模型][12]

----------

## 三、总结



----------

作者 [renqHIT][13]    
2016 年 11月 1日    


  [1]: https://www.datageekers.com/t/topic/103
  [2]: https://www.kaggle.com/c/santander-product-recommendation
  [3]: http://static.zybuluo.com/renqHIT/2r8icoo86qvztp5hvwak062f/image_1b3pnf8vss3k1pu91eov1kli1ivc9.png
  [4]: http://static.zybuluo.com/renqHIT/ivvgq8l7n3w9yxpfi2i95ub8/abhishek_15.png
  [5]: http://static.zybuluo.com/renqHIT/zbmatw2h39mog8og7q5e8dgs/abhishek_16.png
  [6]: http://static.zybuluo.com/renqHIT/hsxu2xeuyv7sah8vv381vacz/abhishek_17.png
  [7]: http://static.zybuluo.com/renqHIT/zml6xjt5fj6udor5b6zumg3t/abhishek_18.png
  [8]: http://static.zybuluo.com/renqHIT/v93xmqcdzn8mxsx5br10tcv7/abhishek_decomp.png
  [9]: https://github.com/abhishekkrthakur/greedyFeatureSelection
  [10]: http://static.zybuluo.com/renqHIT/p3i9nf8ktmf86j7ec36suz66/abhishek_21.png
  [11]: http://static.zybuluo.com/renqHIT/gyr30mjl9t5nuyecfb25kxeh/abhishek_24.png
  [12]: http://static.zybuluo.com/renqHIT/hoxtre5p8fck9z3k5kospdrv/abhishek_26.png
  [13]: http://weibo.com/renqHIT
